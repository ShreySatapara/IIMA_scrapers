{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "weather data.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "esiBi_c3xM6c",
        "outputId": "72035ea0-8786-4896-b561-8694e08326ca"
      },
      "source": [
        "!pip install selenium\n",
        "!apt-get update # to update ubuntu to correctly run apt install\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: selenium in /usr/local/lib/python3.7/dist-packages (3.141.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from selenium) (1.24.3)\n",
            "Get:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Ign:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Ign:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Fetched 252 kB in 2s (102 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "chromium-chromedriver is already the newest version (90.0.4430.72-0ubuntu0.18.04.1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 54 not upgraded.\n",
            "cp: '/usr/lib/chromium-browser/chromedriver' and '/usr/bin/chromedriver' are the same file\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lokHVEWwxPwO",
        "outputId": "d216f21b-5731-4615-ca9c-b62c099d05c0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Zn0OVBvxR8v"
      },
      "source": [
        "import urllib3\n",
        "import requests\n",
        "import json\n",
        "import urllib.request\n",
        "import re\n",
        "import time\n",
        "import logging\n",
        "import pandas\n",
        "from collections import OrderedDict\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "import sys\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.common.action_chains import ActionChains\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.common.exceptions import StaleElementReferenceException\n",
        "import math\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pd5xTE-HxUCS"
      },
      "source": [
        "import sys\n",
        "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n",
        "from selenium import webdriver\n",
        "chrome_options = Options()\n",
        "chrome_options.add_argument(\"--headless\")\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "driver = webdriver.Chrome('/usr/lib/chromium-browser/chromedriver', options=chrome_options)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Chi7etqRxVR6"
      },
      "source": [
        "driver.get('https://www.wunderground.com/history/daily/us/ny/latham/KALB/date/2001-1-1')\n",
        "time.sleep(3)\n",
        "driver.find_element_by_id('wuSettings').click()\n",
        "time.sleep(1)\n",
        "driver.find_element_by_class_name('button-group').find_elements_by_class_name('button')[1].click()\n",
        "time.sleep(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdRKf_4BJaTm"
      },
      "source": [
        "zipcodes = {\n",
        "    1201: 'https://www.wunderground.com/history/daily/us/ma/pittsfield/KPSF' #add only unique ones\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUvSLnauxY4w"
      },
      "source": [
        "def get_hourly(link, year,mon,day):\n",
        "    processed_data = []\n",
        "    driver.get(link+'/date/'+str(year)+'-'+str(mon)+'-'+str(day))\n",
        "    time.sleep(3)\n",
        "    raw_data = driver.find_elements_by_class_name('mat-row.cdk-row.ng-star-inserted')\n",
        "    summary = driver.find_element_by_tag_name('tbody').text.split('\\n')\n",
        "    \n",
        "    day_entries.append({'day':str(year)+'-'+str(mon)+'-'+str(day),  \n",
        "                        'entries':len(raw_data),\n",
        "                        'historic_average_high': summary[0].split()[3],\n",
        "                        'historic_average_low': summary[1].split()[3],\n",
        "                        'record_high': summary[0].split()[4],\n",
        "                        'record_low': summary[1].split()[4]})\n",
        "    print(str(year)+'-'+str(mon)+'-'+str(day), len(raw_data))\n",
        "    for i in raw_data:\n",
        "        x = {}\n",
        "        s = i.text.split()\n",
        "        x['Zipcode'] = str(zc) if zc>10000 else '0'+str(zc)\n",
        "        x['Date']=str(year)+'-'+str(mon)+'-'+str(day)\n",
        "        x['Weather_Condition'] = ' '.join(s[17:])\n",
        "        x['Time'] = s[0]+' '+s[1]\n",
        "        x['Temperature'] = s[2]\n",
        "        x['Dew Point'] = s[4]\n",
        "        x['Humidity'] = s[6]\n",
        "        x['Wind'] = s[8]\n",
        "        x['Wind Speed'] = s[9]\n",
        "        x['Wind Gust'] = s[11]\n",
        "        x['Pressure'] = s[13]\n",
        "        x['PRECIPITATION'] = s[15]\n",
        "        processed_data.append(x)\n",
        "    return processed_data\n",
        "\n",
        "def get_zipcode_data(link):\n",
        "    for i in range(2001,2007):\n",
        "        for j in range(1,13):\n",
        "            if j in [1,3,5,7,8,10,12]:\n",
        "                for k in range(1,32):\n",
        "                     for d in get_hourly(link, i,j,k):\n",
        "                            hourly_data.append(d)\n",
        "            if j in [4,6,9,11]:\n",
        "                for k in range(1,31):\n",
        "                    for d in get_hourly(link, i,j,k):\n",
        "                            hourly_data.append(d)\n",
        "            if j in [2]:\n",
        "                if(i==2004):\n",
        "                    for k in range(1,30):\n",
        "                        for d in get_hourly(link, i,j,k):\n",
        "                            hourly_data.append(d)\n",
        "                else:\n",
        "                    for k in range(1,29):\n",
        "                        for d in get_hourly(link, i,j,k):\n",
        "                            hourly_data.append(d)\n",
        "        df = pd.DataFrame(hourly_data, columns = hourly_data[0].keys())\n",
        "        print('writing data for '+str(zc)+' ' + str(i))\n",
        "        df.to_excel(\"/content/drive/MyDrive/weather/\"+str(zc) if zc>10000 else '0'+str(zc)+\"_Raw_Hourly.xlsx\", index=None)\n",
        "        df = pd.DataFrame(day_entries, columns = day_entries[0].keys())\n",
        "        print(str(zc)+' ' + str(i)+' complete. now writing file for entries per date')\n",
        "        df.to_excel(\"/content/drive/MyDrive/weather/\"+str(zc) if zc>10000 else '0'+str(zc)+\"_Entries_Hourly.xlsx\", index=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VJpl0gK6i1Q"
      },
      "source": [
        "for zc in zipcodes.keys():\n",
        "    hourly_data = []\n",
        "    day_entries = []\n",
        "    get_zipcode_data(zipcodes[zc])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}